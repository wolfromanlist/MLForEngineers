{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22fba655",
   "metadata": {},
   "source": [
    "# Projekt\n",
    "\n",
    "## 1. Zielsetzung und Datenverständnis\n",
    "\n",
    "In diesem Projekt wenden wir die Konzepte aus den vorherigen Notebooks auf einen echten Datensatz an. Ziel ist es, mithilfe der bisher erlernten Methoden ein einfaches maschinelles Lernmodell zu entwickeln, das auf Basis physikalischer und materialtechnischer Eigenschaften vorhersagen kann, ob eine Steckverbindung im Laufe der Zeit einen kritischen Widerstand überschreiten wird. Wir werden nicht nur vorhersagen können, **ob** ein kritischer elektrischer Widerstand überschritten wird, sondern auch **wann** dies voraussichtlich geschieht.\n",
    "\n",
    "### Der Kontext\n",
    "\n",
    "Steckverbindungen sind essenzielle Bauteile in vielen technischen Systemen – von der Automobilindustrie bis zur Elektronikfertigung. Mit der Zeit und unter Belastung (z. B. durch Vibration oder Temperaturwechsel) kann der elektrische Kontaktwiderstand steigen. Überschreitet er einen bestimmten Schwellenwert (meist 300 mΩ), gilt die Verbindung typischerweise als defekt.\n",
    "\n",
    "Der vorliegende Datensatz enthält Informationen zu mehreren Steckverbindungen, darunter:\n",
    "\n",
    "* **Materialeigenschaften** wie die Art der Beschichtung (Silber, Zinn) oder das Vorhandensein einer Zwischenschicht (Nickel),\n",
    "* **Prozessparameter** wie Normalkraft, Frequenz und Bewegungshub,\n",
    "* sowie die **Zyklenzahl**, bei der ein bestimmter Widerstandsschwellenwert (z. B. 1 mΩ, 20 mΩ, …, 300 mΩ) erstmals überschritten wurde – falls überhaupt.\n",
    "\n",
    "### Das Ziel\n",
    "\n",
    "Ihr werdet ein **zweistufiges Modell** entwickeln:\n",
    "\n",
    "1. **Klassifikation**:\n",
    "   Vorhersage, ob eine Steckverbindung **überhaupt** den Schwellenwert von 300 mΩ überschreiten wird.\n",
    "   → Zielgröße: *Ja (1)* oder *Nein (0)*\n",
    "\n",
    "2. **Regression** (für die vorhergesagten \"Ja\"-Fälle):\n",
    "   Schätzung, **nach wie vielen Belastungszyklen** der Widerstand von 300 mΩ erreicht wird.\n",
    "   → Zielgröße: *Zyklenanzahl*\n",
    "\n",
    "Diese Kombination ermöglicht es, zunächst risikobehaftete Steckverbindungen zu identifizieren – und anschließend genauer abzuschätzen, wann voraussichtlich ein kritischer Zustand eintritt, um Wartungsarbeiten einzuleiten.\n",
    "\n",
    "### Der Datensatz\n",
    "\n",
    "Die Datei `Schwellenwerte-Table 1.csv` enthält pro Zeile eine Steckverbindung mit:\n",
    "\n",
    "* einem **Dateinamen** (`Datei`)\n",
    "* Angaben zu **Material und Prozessparametern**\n",
    "* Zyklenzahlen, bei denen bestimmte **Ohm-Schwellen überschritten wurden** (z. B. `Zyklus_300_mOhm`)\n",
    "\n",
    "  * Ein Wert von **-1** bedeutet: Schwelle wurde **nicht** überschritten.\n",
    "\n",
    "## Aufgabe 1: Überblick verschaffen\n",
    "\n",
    "Lade die Datei `Schwellenwerte-Table 1.csv` mit `pandas` und verschaffe dir einen Überblick:\n",
    "\n",
    "* Gib die Form des DataFrames mit `.shape` aus\n",
    "* Zeige die ersten 5 Zeilen mit `.head()`\n",
    "* Liste die Spaltennamen auf\n",
    "* Gib eine Übersicht der statistischen Kenngrößen aus (max, min, std, mean, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0feb6839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 14)\n",
      "                                Datei Beschichtung_Ag_Sn Zwischenschicht_Ni  \\\n",
      "0    AgCu-200µm-1N-75000zyklen-V1.txt               Nein               Nein   \n",
      "1   AgCu-200µm-2.5N-6100zyklen-V1.txt               Nein               Nein   \n",
      "2  AgCu-200µm-2.5N-29000zyklen-V1.txt               Nein               Nein   \n",
      "3     AgCu-200µm-5N-3000zyklen-V1.txt               Nein               Nein   \n",
      "4    AgCu-200µm-5N-13000zyklen-V1.txt               Nein               Nein   \n",
      "\n",
      "   Normalkraft  Frequenz  Bewegungshub  Zyklus_1_mOhm  Zyklus_2_mOhm  \\\n",
      "0          1.0         1           200              0             16   \n",
      "1          2.5         1           200              0              0   \n",
      "2          2.5         1           200              0           6810   \n",
      "3          5.0         1           200              0             -1   \n",
      "4          5.0         1           200              0             -1   \n",
      "\n",
      "   Zyklus_5_mOhm  Zyklus_10_mOhm  Zyklus_20_mOhm  Zyklus_50_mOhm  \\\n",
      "0        15360.0           42482           50456           50729   \n",
      "1            0.0               0               0               0   \n",
      "2        24394.0           26294           26329           26776   \n",
      "3           -1.0              -1              -1              -1   \n",
      "4           -1.0              -1              -1              -1   \n",
      "\n",
      "   Zyklus_100_mOhm  Zyklus_300_mOhm  \n",
      "0            50967            51637  \n",
      "1                0                0  \n",
      "2            27980            28576  \n",
      "3               -1               -1  \n",
      "4               -1               -1  \n",
      "Index(['Datei', 'Beschichtung_Ag_Sn', 'Zwischenschicht_Ni', 'Normalkraft',\n",
      "       'Frequenz', 'Bewegungshub', 'Zyklus_1_mOhm', 'Zyklus_2_mOhm',\n",
      "       'Zyklus_5_mOhm', 'Zyklus_10_mOhm', 'Zyklus_20_mOhm', 'Zyklus_50_mOhm',\n",
      "       'Zyklus_100_mOhm', 'Zyklus_300_mOhm'],\n",
      "      dtype='object')\n",
      "       Normalkraft   Frequenz  Bewegungshub  Zyklus_1_mOhm  Zyklus_2_mOhm  \\\n",
      "count    99.000000  99.000000     99.000000      99.000000      99.000000   \n",
      "mean      2.454545   1.929293    112.121212      81.212121     445.262626   \n",
      "std       2.579443   0.257639     40.463456     286.453838    1087.835115   \n",
      "min       1.000000   1.000000    100.000000      -1.000000      -1.000000   \n",
      "25%       2.000000   2.000000    100.000000       0.000000       2.000000   \n",
      "50%       2.000000   2.000000    100.000000       0.000000       3.000000   \n",
      "75%       2.000000   2.000000    100.000000       4.000000     111.500000   \n",
      "max      20.000000   2.000000    400.000000    1538.000000    6810.000000   \n",
      "\n",
      "       Zyklus_5_mOhm  Zyklus_10_mOhm  Zyklus_20_mOhm  Zyklus_50_mOhm  \\\n",
      "count      98.000000       99.000000       99.000000       99.000000   \n",
      "mean     2561.826531     4353.989899     7594.151515     9083.090909   \n",
      "std      5286.412737     8931.732210    16030.835351    20405.901390   \n",
      "min        -1.000000       -1.000000       -1.000000       -1.000000   \n",
      "25%         6.000000       -0.500000       -1.000000       -1.000000   \n",
      "50%       189.000000      196.000000      264.000000       85.000000   \n",
      "75%      2328.000000     3369.500000     9485.500000     9474.000000   \n",
      "max     26338.000000    42482.000000    99172.000000   140330.000000   \n",
      "\n",
      "       Zyklus_100_mOhm  Zyklus_300_mOhm  \n",
      "count        99.000000        99.000000  \n",
      "mean      16553.909091     17775.929293  \n",
      "std       39371.567489     55885.538706  \n",
      "min          -1.000000        -1.000000  \n",
      "25%          -1.000000        -1.000000  \n",
      "50%          -1.000000        -1.000000  \n",
      "75%       13755.000000       786.500000  \n",
      "max      263514.000000    400292.000000  \n"
     ]
    }
   ],
   "source": [
    "### Importiere pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Lade die CSV-Datei in einen DataFrame\n",
    "df = pd.read_csv('../Data/Schwellenwerte-Table 1.csv')\n",
    "\n",
    "# Zeige die Form des DataFrames, die ersten 5 Zeilen, die Spaltennamen und eine Übersicht der statistischen Kenngrößen an\n",
    "print(df.shape)\n",
    "\n",
    "# Zeige die ersten 5 Zeilen des DataFrames\n",
    "print(df.head())\n",
    "\n",
    "# Liste die Spaltennamen auf\n",
    "print(df.columns)\n",
    "\n",
    "# Gib eine Übersicht der statistischen Kenngrößen aus\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121432a",
   "metadata": {},
   "source": [
    "## Aufgabe 2: Fehlende Werte handlen und Datentypen überprüfen\n",
    "\n",
    "Untersuche die fehlenden Werte:\n",
    "* Gib die Anzahl der fehlenden Werte pro Spalte aus. Entscheide, was mit fehlenden Daten zu tun ist, falls sie existieren.\n",
    "* Ersetze dann alle Werte -1 durch `pd.NA`, um deutlich zu machen, dass der dazugehörige Widerstand nicht erreicht wurde.\n",
    "* Gib die Datentypen aller Spalten mit `.dtypes` aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1266d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datei                 0\n",
      "Beschichtung_Ag_Sn    0\n",
      "Zwischenschicht_Ni    0\n",
      "Normalkraft           0\n",
      "Frequenz              0\n",
      "Bewegungshub          0\n",
      "Zyklus_1_mOhm         0\n",
      "Zyklus_2_mOhm         0\n",
      "Zyklus_5_mOhm         1\n",
      "Zyklus_10_mOhm        0\n",
      "Zyklus_20_mOhm        0\n",
      "Zyklus_50_mOhm        0\n",
      "Zyklus_100_mOhm       0\n",
      "Zyklus_300_mOhm       0\n",
      "dtype: int64\n",
      "Datei                  object\n",
      "Beschichtung_Ag_Sn     object\n",
      "Zwischenschicht_Ni     object\n",
      "Normalkraft           float64\n",
      "Frequenz                int64\n",
      "Bewegungshub            int64\n",
      "Zyklus_1_mOhm         float64\n",
      "Zyklus_2_mOhm         float64\n",
      "Zyklus_5_mOhm         float64\n",
      "Zyklus_10_mOhm        float64\n",
      "Zyklus_20_mOhm        float64\n",
      "Zyklus_50_mOhm        float64\n",
      "Zyklus_100_mOhm       float64\n",
      "Zyklus_300_mOhm       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Untersuche die fehlenden Werte\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Droppe die Reihe mit dem fehlenden Wert in der Spalte 'Zyklus_5_mOhm'\n",
    "df = df.dropna()\n",
    "\n",
    "# Ersetze alle Werte -1 durch pd.NA \n",
    "df.replace(-1, np.nan, inplace=True)\n",
    "\n",
    "# Zeige die Datentypen aller Spalten\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d39d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Alle echten NaNs entfernt und -1 korrekt durch NaN ersetzt. \n",
      " -------------------- \n",
      " Info: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 98 entries, 0 to 98\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Datei               98 non-null     object \n",
      " 1   Beschichtung_Ag_Sn  98 non-null     object \n",
      " 2   Zwischenschicht_Ni  98 non-null     object \n",
      " 3   Normalkraft         98 non-null     float64\n",
      " 4   Frequenz            98 non-null     int64  \n",
      " 5   Bewegungshub        98 non-null     int64  \n",
      " 6   Zyklus_1_mOhm       96 non-null     float64\n",
      " 7   Zyklus_2_mOhm       91 non-null     float64\n",
      " 8   Zyklus_5_mOhm       89 non-null     float64\n",
      " 9   Zyklus_10_mOhm      74 non-null     float64\n",
      " 10  Zyklus_20_mOhm      63 non-null     float64\n",
      " 11  Zyklus_50_mOhm      56 non-null     float64\n",
      " 12  Zyklus_100_mOhm     45 non-null     float64\n",
      " 13  Zyklus_300_mOhm     30 non-null     float64\n",
      "dtypes: float64(9), int64(2), object(3)\n",
      "memory usage: 11.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from scripts.checker import check_handling_missing_values\n",
    "\n",
    "check_handling_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392d27d",
   "metadata": {},
   "source": [
    "## Aufgabe 3: Zielvariable erstellen\n",
    "\n",
    "Erstelle eine Spalte namens `target`, die wie folgt definiert ist:\n",
    "\n",
    "* **1**, wenn `Zyklus_300_mOhm` einen Wert größer als 0 enthält\n",
    "* **0**, wenn der Wert 0 oder NaN ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46aef3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = (df[\"Zyklus_300_mOhm\"] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18966a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Zielvariable korrekt erstellt: \n",
      "     target\n",
      "0        1\n",
      "1        0\n",
      "2        1\n",
      "3        0\n",
      "4        0\n",
      "..     ...\n",
      "94       1\n",
      "95       0\n",
      "96       0\n",
      "97       0\n",
      "98       0\n",
      "\n",
      "[98 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from scripts.checker import check_target_column\n",
    "check_target_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061af044",
   "metadata": {},
   "source": [
    "## Aufgabe 4: One-Hot-Encoding und Standardisierung\n",
    "\n",
    "Bereite den Datensatz für das Modell vor:\n",
    "\n",
    "1. Wandle **kategorische Variablen** in numerische mit One-Hot-Encoding um. Vermeide Multikollinearität.\n",
    "2. Standardisiere alle **numerischen Features**, z. B. mit `StandardScaler` von scikit-learn\n",
    "3. Speichere die verarbeiteten Features in einer neuen Variable `X_processed`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c21b737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Features\n",
    "features = [\"Beschichtung_Ag_Sn\", \"Zwischenschicht_Ni\", \"Normalkraft\", \"Frequenz\", \"Bewegungshub\", \"Zyklus_1_mOhm\", \"Zyklus_2_mOhm\", \"Zyklus_5_mOhm\", \"Zyklus_10_mOhm\", \"Zyklus_20_mOhm\", \"Zyklus_50_mOhm\", \"Zyklus_100_mOhm\", \"Zyklus_300_mOhm\"]\n",
    "\n",
    "# Nur relevante Features extrahieren\n",
    "X = df[features].copy()\n",
    "\n",
    "# One-Hot-Encoding für kategorische Variablen\n",
    "X_encoded = pd.get_dummies(X, columns=[\"Beschichtung_Ag_Sn\", \"Zwischenschicht_Ni\"], drop_first=True)\n",
    "\n",
    "# Standardisierung numerischer Spalten\n",
    "numerical_cols = [\"Normalkraft\", \"Frequenz\", \"Bewegungshub\", \"Zyklus_1_mOhm\", \"Zyklus_2_mOhm\", \"Zyklus_5_mOhm\", \"Zyklus_10_mOhm\", \"Zyklus_20_mOhm\", \"Zyklus_50_mOhm\", \"Zyklus_100_mOhm\", \"Zyklus_300_mOhm\"]\n",
    "scaler = StandardScaler()\n",
    "X_encoded[numerical_cols] = scaler.fit_transform(X_encoded[numerical_cols])\n",
    "\n",
    "# Fertige Matrix\n",
    "X_processed = X_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b592844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Normalkraft  Frequenz  Bewegungshub  Zyklus_1_mOhm  Zyklus_2_mOhm  \\\n",
      "0    -0.565788 -3.605551      2.169753      -0.289815      -0.418103   \n",
      "1     0.015826 -3.605551      2.169753      -0.289815      -0.432383   \n",
      "2     0.015826 -3.605551      2.169753      -0.289815       5.645553   \n",
      "3     0.985183 -3.605551      2.169753      -0.289815            NaN   \n",
      "4     0.985183 -3.605551      2.169753      -0.289815            NaN   \n",
      "\n",
      "   Zyklus_5_mOhm  Zyklus_10_mOhm  Zyklus_20_mOhm  Zyklus_50_mOhm  \\\n",
      "0       2.299795        3.720450        2.065106        1.396146   \n",
      "1      -0.517401       -0.591232       -0.639780       -0.646652   \n",
      "2       3.956731        2.077460        0.771686        0.431586   \n",
      "3            NaN             NaN             NaN             NaN   \n",
      "4            NaN             NaN             NaN             NaN   \n",
      "\n",
      "   Zyklus_100_mOhm  Zyklus_300_mOhm  Beschichtung_Ag_Sn_Nein  \\\n",
      "0         0.282468        -0.079533                     True   \n",
      "1        -0.707176        -0.664062                     True   \n",
      "2        -0.163879        -0.340583                     True   \n",
      "3              NaN              NaN                     True   \n",
      "4              NaN              NaN                     True   \n",
      "\n",
      "   Zwischenschicht_Ni_Nein  \n",
      "0                     True  \n",
      "1                     True  \n",
      "2                     True  \n",
      "3                     True  \n",
      "4                     True  \n"
     ]
    }
   ],
   "source": [
    "print(X_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbac5dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berechnete Mittelwerte und Standardabweichungen:\n",
      "Mittelwerte: \n",
      " Normalkraft        6.060911e-17\n",
      "Frequenz           1.212182e-16\n",
      "Bewegungshub       1.246169e-17\n",
      "Zyklus_1_mOhm      3.816392e-17\n",
      "Zyklus_2_mOhm      4.880101e-18\n",
      "Zyklus_5_mOhm      4.989766e-18\n",
      "Zyklus_10_mOhm     4.650934e-17\n",
      "Zyklus_20_mOhm     1.938485e-17\n",
      "Zyklus_50_mOhm     5.947623e-18\n",
      "Zyklus_100_mOhm    4.934325e-17\n",
      "Zyklus_300_mOhm    5.921189e-17\n",
      "dtype: float64\n",
      "Standardabweichungen: \n",
      " Normalkraft        1.0\n",
      "Frequenz           1.0\n",
      "Bewegungshub       1.0\n",
      "Zyklus_1_mOhm      1.0\n",
      "Zyklus_2_mOhm      1.0\n",
      "Zyklus_5_mOhm      1.0\n",
      "Zyklus_10_mOhm     1.0\n",
      "Zyklus_20_mOhm     1.0\n",
      "Zyklus_50_mOhm     1.0\n",
      "Zyklus_100_mOhm    1.0\n",
      "Zyklus_300_mOhm    1.0\n",
      "dtype: float64\n",
      "✅ One-Hot-Encoding & Standardisierung korrekt!\n"
     ]
    }
   ],
   "source": [
    "from scripts.checker import check_preprocessing\n",
    "check_preprocessing(X_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8269e3",
   "metadata": {},
   "source": [
    "## Aufgabe 5: Daten in Trainings- und Testmenge aufteilen\n",
    "\n",
    "Teile die Features `X_prepared` und Labels `df[\"target\"]` in Trainings- und Testdaten auf.\n",
    "\n",
    "Anforderungen:\n",
    "* 80 % Training, 20 % Test\n",
    "* Speichere die Arrays als:\n",
    "  - `X_train`, `X_test`\n",
    "  - `y_train`, `y_test`\n",
    "* Setze `random_state=42` für Reproduzierbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78cdf6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14fd0669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Aufteilung erfolgreich!\n"
     ]
    }
   ],
   "source": [
    "### Überprüft eure Lösung\n",
    "from scripts.checker import check_split\n",
    "check_split(X_train, X_test, y_train, y_test, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b13d7c",
   "metadata": {},
   "source": [
    "## Aufgabe 6: Logistisches Regressionsmodell trainieren\n",
    "\n",
    "Trainiere ein logistisches Regressionsmodell auf den Trainingsdaten.\n",
    "\n",
    "Anforderungen:\n",
    "* Verwende `LogisticRegression` aus `sklearn.linear_model`\n",
    "* Speichere das Modell in einer Variable `model`\n",
    "* Trainiere mit `.fit(X_train, y_train)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eda2910a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python Projects/scvenv/lib/python3.13/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python Projects/scvenv/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1222\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1222\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/Python Projects/scvenv/lib/python3.13/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/Python Projects/scvenv/lib/python3.13/site-packages/sklearn/utils/validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m     )\n\u001b[1;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[0;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/Python Projects/scvenv/lib/python3.13/site-packages/sklearn/utils/validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[0;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[0;32m~/Python Projects/scvenv/lib/python3.13/site-packages/sklearn/utils/validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python Projects/scvenv/lib/python3.13/site-packages/sklearn/utils/validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.checker import check_model_training\n",
    "# check_model_training(<>Hier euer model, X_train, y_train einfügen<>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f456933",
   "metadata": {},
   "source": [
    "## Aufgabe 7: Scatterplot der Vorhersagen\n",
    "\n",
    "Visualisiere die Modellvorhersagen mithilfe eines Scatterplots:\n",
    "\n",
    "Schritte:\n",
    "1. Wähle zwei numerische Features, z. B. `Kontaktkraft_N` und `Steckzyklen`\n",
    "2. Plotte die Testdaten in diesen zwei Dimensionen\n",
    "3. Farbe: Nutze `model.predict(X_test)` als Farbe (0 oder 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd0c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hier ist Platz für eure Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23cc602",
   "metadata": {},
   "source": [
    "## Aufgabe 8: Modell evaluieren\n",
    "\n",
    "Bewerte die Qualität deiner Vorhersagen auf dem Testdatensatz.\n",
    "\n",
    "Berechne folgende Metriken mit scikit-learn:\n",
    "\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- Confusion Matrix\n",
    "- ROC-AUC\n",
    "\n",
    "> Hinweis: Verwende `model.predict(X_test)` für die Klassenvorhersage und `model.predict_proba(X_test)[:, 1]` für Wahrscheinlichkeiten.\n",
    "\n",
    "Speichere die Vorhersagen in `y_pred` und die Wahrscheinlichkeiten in `y_prob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28f53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hier ist Platz für eure Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b19d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Überprüft eure Lösung\n",
    "from scripts.checker import check_metrics\n",
    "# check_metrics(<>Hier eure y_test, y_pred, y_prob einfügen<>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d61cf6",
   "metadata": {},
   "source": [
    "## Aufgabe 9: Interpretation der Feature-Gewichte\n",
    "\n",
    "Nutze die Koeffizienten des Modells, um zu verstehen, welche Features das Modell beeinflussen.\n",
    "\n",
    "Schritte:\n",
    "1. Erstelle ein DataFrame, das die Features (`X_prepared.columns`) den zugehörigen Koeffizienten (`model.coef_`) gegenüberstellt.\n",
    "2. Sortiere es nach der Stärke des Einflusses (positiv oder negativ).\n",
    "3. Stelle die Top-10 wichtigsten Features in einem Balkendiagramm dar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a0c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hier ist Platz für eure Lösung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505df83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Überprüft eure Lösung\n",
    "from scripts.checker import check_coefficients\n",
    "# check_coefficients(<>Hier euer model, X_prepared einfügen<>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvenv",
   "language": "python",
   "name": "scvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
